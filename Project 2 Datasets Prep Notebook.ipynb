{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a604609f",
   "metadata": {},
   "source": [
    "# Dataset Pipeline — Two Original Classification Problems (Data Prep Only)\n",
    "\n",
    "**Scope:** This notebook completes the *dataset portion only* of the project for two original classification problems (no Kaggle/UCI/HF).\n",
    "It documents **sources**, **ethics**, **quirks**, **descriptive stats & visuals**, **cleaning**, **encoding**, **scaling**, and creates **engineered features** (≥3 per dataset).\n",
    "*Modeling (Logistic Regression from-scratch, sklearn baselines, SVM, Naive Bayes) will be added later.*\n",
    "\n",
    "---\n",
    "\n",
    "## How to Run (Reproducible)\n",
    "1. Open in **Colab** or local **Jupyter** with internet access.\n",
    "2. Run cells top to bottom.\n",
    "3. The notebook downloads raw samples (≥10k rows each) via Socrata SODA API, saves **raw** and **processed** CSVs, and renders EDA plots.\n",
    "4. Random seeds and library versions are logged.\n",
    "5. If you encounter API throttling, reduce `PAGE_SIZE` or `MAX_ROWS` in the download cells.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081d66cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Setup: Versions & Seeds ===\n",
    "# Purpose: Make runs reproducible and transparent about environment.\n",
    "import sys, platform, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "print({\n",
    "    \"python\": sys.version.split()[0],\n",
    "    \"platform\": platform.platform(),\n",
    "    \"pandas\": pd.__version__,\n",
    "    \"numpy\": np.__version__,\n",
    "    \"matplotlib\": plt.matplotlib.__version__,\n",
    "    \"requests\": requests.__version__,\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c8ca6a2",
   "metadata": {},
   "source": [
    "---\n",
    "# Dataset A — NYC Yellow Taxi Trips (Original Source)\n",
    "\n",
    "### Source & Documentation\n",
    "- **Origin:** NYC Taxi & Limousine Commission (TLC) via **NYC Open Data**  \n",
    "  Public documentation: TLC Trip Record Data  \n",
    "  Example dataset (2023): NYC Open Data — 2023 Yellow Taxi Trip Data (`4b4i-vvec`)\n",
    "- **Access method:** Socrata SODA API (`/resource/4b4i-vvec.json`) with `$limit`/`$offset` paging\n",
    "- **Why it qualifies:** Non-Kaggle/UCI/HF; millions of rows; many features; clear label can be defined\n",
    "\n",
    "### Proposed Classification Task\n",
    "Predict **generous tipping**: `high_tip = 1` if `tip_percent ≥ 0.20`, else `0`.  \n",
    "We limit to **credit-card** trips (`payment_type=1`) because cash tips are not captured in the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05de22a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Download NYC Yellow Taxi sample (>=10k rows) ===\n",
    "# Purpose: Pull a manageable sample via SODA API to build our dataset locally.\n",
    "# Guidance: Select a minimal set of fields; use paging due to API row caps.\n",
    "import time\n",
    "\n",
    "TLC_BASE = \"https://data.cityofnewyork.us/resource/4b4i-vvec.json\"  # 2023 Yellow Taxi\n",
    "PAGE_SIZE = 20000   # reduce if throttled\n",
    "MAX_ROWS = 20000    # must be >= 3,000\n",
    "\n",
    "fields = [\n",
    "    \"tpep_pickup_datetime\",\"tpep_dropoff_datetime\",\"passenger_count\",\"trip_distance\",\n",
    "    \"PULocationID\",\"DOLocationID\",\"fare_amount\",\"extra\",\"mta_tax\",\"tip_amount\",\n",
    "    \"tolls_amount\",\"improvement_surcharge\",\"total_amount\",\"congestion_surcharge\",\n",
    "    \"payment_type\",\"ratecode_id\"\n",
    "]\n",
    "select = \",\".join(fields)\n",
    "\n",
    "rows = []\n",
    "offset = 0\n",
    "while len(rows) < MAX_ROWS:\n",
    "    params = {\"$select\": select, \"$limit\": PAGE_SIZE, \"$offset\": offset}\n",
    "    r = requests.get(TLC_BASE, params=params, timeout=60)\n",
    "    r.raise_for_status()\n",
    "    batch = r.json()\n",
    "    if not batch:\n",
    "        break\n",
    "    rows.extend(batch)\n",
    "    offset += PAGE_SIZE\n",
    "    # time.sleep(0.2)  # uncomment if API throttles\n",
    "\n",
    "taxi_raw = pd.DataFrame(rows)\n",
    "print(\"Downloaded rows (NYC taxi):\", taxi_raw.shape)\n",
    "taxi_raw.to_csv(\"taxi_raw_2023.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5654a36f",
   "metadata": {},
   "source": [
    "## Data Description & Quirks (Taxi)\n",
    "**Quirks**\n",
    "- Impossible/implausible values (negative fare, zero distance, zero duration)  \n",
    "- Missing `tip_amount` for cash payments → restrict to credit-card records  \n",
    "- Outliers in `trip_distance`, `duration_min`, `total_amount`  \n",
    "- Duration depends on timestamp parsing and timezone/DST edges\n",
    "\n",
    "**Feature & Label Plan**\n",
    "- `duration_min` = (dropoff − pickup) in minutes  \n",
    "- `speed_mph` = `trip_distance` / (`duration_min`/60)  \n",
    "- `tip_percent` = `tip_amount` / (`fare_amount` + 1e-6)  \n",
    "- `hour`, `dow`, `is_weekend` features from pickup datetime  \n",
    "- **Target:** `high_tip` = 1 if `tip_percent ≥ 0.20` else 0 (credit-card trips only)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43901cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Clean & Engineer (NYC Taxi) ===\n",
    "# Steps: parse datetimes, cast numerics, filter plausibility, engineer features, build label.\n",
    "taxi = taxi_raw.copy()\n",
    "\n",
    "# Parse datetimes\n",
    "for c in [\"tpep_pickup_datetime\", \"tpep_dropoff_datetime\"]:\n",
    "    taxi[c] = pd.to_datetime(taxi[c], errors=\"coerce\")\n",
    "\n",
    "# Cast numeric columns\n",
    "num_cols = [\"passenger_count\",\"trip_distance\",\"fare_amount\",\"extra\",\"mta_tax\",\"tip_amount\",\n",
    "            \"tolls_amount\",\"improvement_surcharge\",\"total_amount\",\"congestion_surcharge\",\n",
    "            \"ratecode_id\",\"payment_type\",\"PULocationID\",\"DOLocationID\"]\n",
    "for c in num_cols:\n",
    "    taxi[c] = pd.to_numeric(taxi[c], errors=\"coerce\")\n",
    "\n",
    "# Duration in minutes\n",
    "taxi[\"duration_min\"] = (taxi[\"tpep_dropoff_datetime\"] - taxi[\"tpep_pickup_datetime\"]).dt.total_seconds() / 60.0\n",
    "\n",
    "# Plausibility filters\n",
    "taxi = taxi[\n",
    "    (taxi[\"trip_distance\"] > 0.1) & (taxi[\"trip_distance\"] < 50) &\n",
    "    (taxi[\"duration_min\"] >= 1) & (taxi[\"duration_min\"] <= 180) &\n",
    "    (taxi[\"fare_amount\"] > 2)\n",
    "].copy()\n",
    "\n",
    "# Credit-card only\n",
    "taxi = taxi[(taxi[\"payment_type\"] == 1)].copy()\n",
    "\n",
    "# Engineered features\n",
    "taxi[\"speed_mph\"] = taxi[\"trip_distance\"] / (taxi[\"duration_min\"]/60.0)\n",
    "taxi[\"tip_percent\"] = taxi[\"tip_amount\"] / (taxi[\"fare_amount\"] + 1e-6)\n",
    "taxi[\"hour\"] = taxi[\"tpep_pickup_datetime\"].dt.hour\n",
    "taxi[\"dow\"] = taxi[\"tpep_pickup_datetime\"].dt.dayofweek\n",
    "taxi[\"is_weekend\"] = taxi[\"dow\"].isin([5,6]).astype(int)\n",
    "\n",
    "# Binary label\n",
    "taxi[\"high_tip\"] = (taxi[\"tip_percent\"] >= 0.20).astype(int)\n",
    "\n",
    "# Remove pathological speeds\n",
    "taxi = taxi[(taxi[\"speed_mph\"] > 1) & (taxi[\"speed_mph\"] < 80)]\n",
    "\n",
    "print(\"After cleaning & FE (NYC taxi):\", taxi.shape)\n",
    "taxi.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80984bb6",
   "metadata": {},
   "source": [
    "## Descriptive Stats & Visuals (Taxi)\n",
    "- Summary stats (`describe()`)\n",
    "- Missingness counts\n",
    "- Histograms: `trip_distance`, `duration_min`, `tip_percent`\n",
    "- High-tip rate by hour & weekend\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9853cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === EDA (NYC Taxi) ===\n",
    "key_cols = [\"trip_distance\",\"duration_min\",\"fare_amount\",\"tip_amount\",\"tip_percent\",\"speed_mph\"]\n",
    "print(taxi[key_cols].describe().T)\n",
    "\n",
    "print(\"\\nMissing values (top 10):\\n\", taxi.isna().sum().sort_values(ascending=False).head(10))\n",
    "\n",
    "fig, axes = plt.subplots(1,3, figsize=(12,3))\n",
    "axes[0].hist(taxi[\"trip_distance\"].dropna(), bins=40)\n",
    "axes[0].set_title(\"Trip Distance\")\n",
    "axes[1].hist(taxi[\"duration_min\"].dropna(), bins=40)\n",
    "axes[1].set_title(\"Duration (min)\")\n",
    "axes[2].hist(taxi[\"tip_percent\"].dropna().clip(0,1), bins=40)\n",
    "axes[2].set_title(\"Tip % (clipped 0-1)\")\n",
    "plt.tight_layout(); plt.show()\n",
    "\n",
    "hour_rate = taxi.groupby(\"hour\")[\"high_tip\"].mean()\n",
    "plt.figure(figsize=(5,3)); plt.plot(hour_rate.index, hour_rate.values, marker=\"o\")\n",
    "plt.title(\"High Tip Rate by Hour\"); plt.xlabel(\"Hour\"); plt.ylabel(\"Rate\"); plt.show()\n",
    "\n",
    "wk_rate = taxi.groupby(\"is_weekend\")[\"high_tip\"].mean()\n",
    "plt.figure(figsize=(4,3)); plt.bar([\"Weekday\",\"Weekend\"], wk_rate.values)\n",
    "plt.title(\"High Tip Rate: Weekend vs Weekday\"); plt.ylabel(\"Rate\"); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06718ddb",
   "metadata": {},
   "source": [
    "## Encoding & Scaling (Taxi)\n",
    "- High-cardinality IDs (`PULocationID`, `DOLocationID`, `ratecode_id`) are **frequency-encoded** to avoid huge one-hot matrices.  \n",
    "- Numerical features are standardized for later models.\n",
    "\n",
    "Output saved as `taxi_clean_features.csv`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec640dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Encode & Scale (NYC Taxi) ===\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "taxi_proc = taxi.copy()\n",
    "\n",
    "# Frequency encoding for high-cardinality columns\n",
    "for col in [\"PULocationID\",\"DOLocationID\",\"ratecode_id\"]:\n",
    "    freq = taxi_proc[col].value_counts(normalize=True)\n",
    "    taxi_proc[col+\"_freq\"] = taxi_proc[col].map(freq).fillna(0)\n",
    "\n",
    "X_cols_taxi = [\n",
    "    \"passenger_count\",\"trip_distance\",\"fare_amount\",\"tolls_amount\",\"total_amount\",\n",
    "    \"congestion_surcharge\",\"duration_min\",\"speed_mph\",\"tip_percent\",\"hour\",\"is_weekend\",\n",
    "    \"PULocationID_freq\",\"DOLocationID_freq\",\"ratecode_id_freq\"\n",
    "]\n",
    "y_col_taxi = \"high_tip\"\n",
    "\n",
    "num_cols_scale = [\"passenger_count\",\"trip_distance\",\"fare_amount\",\"tolls_amount\",\"total_amount\",\n",
    "                  \"congestion_surcharge\",\"duration_min\",\"speed_mph\",\"tip_percent\",\"hour\",\n",
    "                  \"PULocationID_freq\",\"DOLocationID_freq\",\"ratecode_id_freq\"]\n",
    "scaler = StandardScaler()\n",
    "taxi_proc[num_cols_scale] = scaler.fit_transform(taxi_proc[num_cols_scale])\n",
    "\n",
    "taxi_proc[X_cols_taxi + [y_col_taxi]].to_csv(\"taxi_clean_features.csv\", index=False)\n",
    "print(\"Saved taxi_clean_features.csv with shape:\", taxi_proc[X_cols_taxi + [y_col_taxi]].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0940e2f7",
   "metadata": {},
   "source": [
    "---\n",
    "# Dataset B — City of Chicago Food Inspections (Original Source)\n",
    "\n",
    "### Source & Documentation\n",
    "- **Origin:** City of Chicago — Department of Public Health, **official open data**  \n",
    "  Program page: Food Establishment Inspection Reports  \n",
    "  API dataset: `https://data.cityofchicago.org/resource/4ijn-s7e5.json`\n",
    "- **Why it qualifies:** Non-Kaggle/UCI/HF; >3,000 rows; many features; clear label\n",
    "\n",
    "### Proposed Classification Task\n",
    "Predict **inspection outcome**: `pass_binary = 1` if `results == \"Pass\"`, else `0` (`Fail`, `Pass w/ Conditions`, etc.).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7292f2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Download Chicago Food Inspections sample (>=10k rows) ===\n",
    "CHI_BASE = \"https://data.cityofchicago.org/resource/4ijn-s7e5.json\"\n",
    "PAGE_SIZE = 20000\n",
    "MAX_ROWS = 20000\n",
    "\n",
    "fields = [\n",
    "    \"inspection_id\",\"inspection_date\",\"dba_name\",\"aka_name\",\"license_\",\n",
    "    \"facility_type\",\"risk\",\"results\",\"violations\",\"address\",\"zip\",\"ward\",\"community_area\",\n",
    "    \"latitude\",\"longitude\"\n",
    "]\n",
    "select = \",\".join(fields)\n",
    "\n",
    "rows = []\n",
    "offset = 0\n",
    "while len(rows) < MAX_ROWS:\n",
    "    params = {\"$select\": select, \"$limit\": PAGE_SIZE, \"$offset\": offset}\n",
    "    r = requests.get(CHI_BASE, params=params, timeout=60)\n",
    "    r.raise_for_status()\n",
    "    batch = r.json()\n",
    "    if not batch:\n",
    "        break\n",
    "    rows.extend(batch)\n",
    "    offset += PAGE_SIZE\n",
    "\n",
    "chi_raw = pd.DataFrame(rows)\n",
    "print(\"Downloaded rows (Chicago):\", chi_raw.shape)\n",
    "chi_raw.to_csv(\"chi_food_raw.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75217768",
   "metadata": {},
   "source": [
    "## Data Description & Quirks (Chicago)\n",
    "**Quirks**\n",
    "- `results` has multiple categories → binarize to Pass vs Not-Pass  \n",
    "- `risk` may be missing/inconsistent (Risk 1/2/3)  \n",
    "- `violations` is semi-structured free text → regex parse for counts  \n",
    "- Multiple rows per `license_` across time → compute longitudinal features\n",
    "\n",
    "**Feature & Label Plan**\n",
    "- `pass_binary` = 1 if `results == 'Pass'`, else 0  \n",
    "- `violation_count` = number of violation codes parsed from text  \n",
    "- `viol_text_len` = length of violations narrative  \n",
    "- `risk_level` = numeric mapping (1=High, 2=Med, 3=Low)  \n",
    "- `month`, `year`, and `days_since_prev` per facility\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656d6862",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Clean & Engineer (Chicago) ===\n",
    "# Steps: parse dates, build label, parse violations, map risk, add temporal features (including gaps).\n",
    "import re\n",
    "chi = chi_raw.copy()\n",
    "\n",
    "# Parse dates\n",
    "chi[\"inspection_date\"] = pd.to_datetime(chi[\"inspection_date\"], errors=\"coerce\")\n",
    "\n",
    "# Binary label\n",
    "chi[\"pass_binary\"] = (chi[\"results\"].astype(str).str.strip().str.lower() == \"pass\").astype(int)\n",
    "\n",
    "# Violation features\n",
    "def count_violation_codes(s):\n",
    "    if pd.isna(s) or not isinstance(s, str):\n",
    "        return 0\n",
    "    return len(re.findall(r'\\b\\d{2}\\.?\\d*\\b', s))\n",
    "\n",
    "chi[\"violation_count\"] = chi[\"violations\"].apply(count_violation_codes)\n",
    "chi[\"viol_text_len\"] = chi[\"violations\"].fillna(\"\").str.len()\n",
    "\n",
    "# Risk mapping\n",
    "risk_map = {\"risk 1 (high)\": 1, \"risk 2 (medium)\": 2, \"risk 3 (low)\": 3}\n",
    "chi[\"risk_level\"] = chi[\"risk\"].astype(str).str.lower().map(risk_map)\n",
    "\n",
    "# Temporal features\n",
    "chi[\"year\"] = chi[\"inspection_date\"].dt.year\n",
    "chi[\"month\"] = chi[\"inspection_date\"].dt.month\n",
    "\n",
    "# Days since previous inspection per facility\n",
    "chi[\"license_\"] = chi[\"license_\"].astype(str)\n",
    "chi = chi.sort_values([\"license_\", \"inspection_date\"])\n",
    "chi[\"prev_date\"] = chi.groupby(\"license_\")[\"inspection_date\"].shift(1)\n",
    "chi[\"days_since_prev\"] = (chi[\"inspection_date\"] - chi[\"prev_date\"]).dt.days\n",
    "\n",
    "print(\"After cleaning & FE (Chicago):\", chi.shape)\n",
    "chi.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c023c1bf",
   "metadata": {},
   "source": [
    "## Descriptive Stats & Visuals (Chicago)\n",
    "- Class balance (Pass rate)  \n",
    "- Describe `violation_count`, `viol_text_len`, `risk_level`, `days_since_prev`  \n",
    "- Pass rate by `risk_level` and by `month`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e675f2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === EDA (Chicago) ===\n",
    "print(\"Pass rate (mean of pass_binary):\", chi[\"pass_binary\"].mean())\n",
    "\n",
    "desc_cols = [\"violation_count\",\"viol_text_len\",\"risk_level\",\"days_since_prev\"]\n",
    "print(chi[desc_cols].describe(include=\"all\").T)\n",
    "\n",
    "fig, axes = plt.subplots(1,3, figsize=(12,3))\n",
    "axes[0].hist(chi[\"violation_count\"].dropna(), bins=30)\n",
    "axes[0].set_title(\"Violation Count\")\n",
    "axes[1].hist(chi[\"viol_text_len\"].dropna().clip(0,2000), bins=30)\n",
    "axes[1].set_title(\"Violations Text Length\")\n",
    "axes[2].hist(chi[\"days_since_prev\"].dropna().clip(0,365*2), bins=30)\n",
    "axes[2].set_title(\"Days Since Previous Inspection\")\n",
    "plt.tight_layout(); plt.show()\n",
    "\n",
    "risk_rate = chi.groupby(\"risk_level\")[\"pass_binary\"].mean()\n",
    "plt.figure(figsize=(4,3))\n",
    "plt.bar([str(int(x)) for x in risk_rate.index.fillna(-1)], risk_rate.values)\n",
    "plt.title(\"Pass Rate by Risk Level\"); plt.xlabel(\"Risk Level\"); plt.ylabel(\"Pass Rate\"); plt.show()\n",
    "\n",
    "month_rate = chi.groupby(\"month\")[\"pass_binary\"].mean()\n",
    "plt.figure(figsize=(5,3))\n",
    "plt.plot(month_rate.index, month_rate.values, marker=\"o\")\n",
    "plt.title(\"Pass Rate by Month\"); plt.xlabel(\"Month\"); plt.ylabel(\"Pass Rate\"); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84be729e",
   "metadata": {},
   "source": [
    "## Encoding & Scaling (Chicago)\n",
    "- Minimal numeric feature set is standardized for later models.  \n",
    "- Optional one-hot encoding for `facility_type` can be added during modeling to control dimensionality.\n",
    "\n",
    "Output saved as `chi_food_clean_features.csv`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c290bb3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Encode & Scale (Chicago) ===\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "chi_proc = chi.copy()\n",
    "X_cols_chi = [\"violation_count\",\"viol_text_len\",\"risk_level\",\"month\",\"days_since_prev\"]\n",
    "y_col_chi = \"pass_binary\"\n",
    "\n",
    "# Median impute numerics before scaling\n",
    "for c in X_cols_chi:\n",
    "    if chi_proc[c].isna().any():\n",
    "        chi_proc[c] = chi_proc[c].fillna(chi_proc[c].median())\n",
    "\n",
    "scaler_chi = StandardScaler()\n",
    "chi_proc[X_cols_chi] = scaler_chi.fit_transform(chi_proc[X_cols_chi])\n",
    "\n",
    "chi_proc[X_cols_chi + [y_col_chi]].to_csv(\"chi_food_clean_features.csv\", index=False)\n",
    "print(\"Saved chi_food_clean_features.csv with shape:\", chi_proc[X_cols_chi + [y_col_chi]].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca5e167",
   "metadata": {},
   "source": [
    "---\n",
    "## Sources & Ethics\n",
    "\n",
    "**Dataset A — NYC Yellow Taxi Trips**  \n",
    "- **Source:** NYC Taxi & Limousine Commission (TLC) via NYC Open Data  \n",
    "- **Access Method:** Socrata SODA API endpoint for 2023 Yellow Taxi Trip Data  \n",
    "- **License/Terms:** Public data provided for research and transparency by NYC Open Data.  \n",
    "- **Ethical Considerations:**  \n",
    "  - Data are de-identified, but location/time patterns can still be sensitive.  \n",
    "  - To mitigate re-identification risks, exact timestamps and raw coordinates were not used directly; instead, aggregated temporal features (hour, day-of-week) and frequency-encoded pickup/dropoff zones were created.  \n",
    "  - Analysis is intended for service improvement and academic purposes, not for stigmatizing neighborhoods or individuals.  \n",
    "\n",
    "**Dataset B — Chicago Food Inspections**  \n",
    "- **Source:** City of Chicago, Department of Public Health (Food Establishment Inspection Reports)  \n",
    "- **Access Method:** Socrata SODA API endpoint for Food Inspections data  \n",
    "- **License/Terms:** Public records provided for transparency and accountability by the City of Chicago.  \n",
    "- **Ethical Considerations:**  \n",
    "  - While the dataset is public, results should not be used to stigmatize specific businesses or communities.  \n",
    "  - Inspections reflect both establishment practices and inspector discretion/scheduling; any predictive modeling should acknowledge potential biases in data collection.  \n",
    "  - Features engineered (e.g., violation counts, text length, risk level) are intended to support aggregate insights rather than punitive labeling of individual establishments.  \n",
    "\n",
    "**General Notes**  \n",
    "- Both datasets are official open data, not sourced from Kaggle, UCI, or similar repositories.  \n",
    "- Bias and fairness must be considered: historical inequities in inspection or tipping patterns may be reflected in the models.  \n",
    "- Privacy risks are mitigated by aggregation, feature transformation, and adherence to the terms of each portal.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8b5e02",
   "metadata": {},
   "source": [
    "## Artifacts Produced\n",
    "- `taxi_raw_2023.csv` — raw sample from NYC TLC (≈20k rows)  \n",
    "- `taxi_clean_features.csv` — cleaned & engineered feature matrix + label (Taxi)  \n",
    "- `chi_food_raw.csv` — raw sample from Chicago Food Inspections (≈20k rows)  \n",
    "- `chi_food_clean_features.csv` — cleaned & engineered feature matrix + label (Chicago)\n",
    "\n",
    "> These files are ready inputs for the modeling stage of the assignment.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
